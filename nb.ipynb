{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, accuracy_score, plot_roc_curve,\\\n",
    "                             precision_recall_curve, plot_precision_recall_curve, f1_score, average_precision_score,\\\n",
    "                             hinge_loss, precision_score, recall_score, classification_report\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate\n",
    "from sklearn.metrics import make_scorer, accuracy_score, average_precision_score, f1_score,\\\n",
    "                            log_loss, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize, LabelBinarizer\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmnist = fetch_openml(\"Fashion-MNIST\", data_home=\"./fmnist\", cache=True)\n",
    "classes = [str(x) for x in range(0, 10)]\n",
    "def mk_dataset(total, fmnist=fmnist, classes=classes):\n",
    "    samples = int(fmnist.data.shape[0]*total)\n",
    "    return resample(fmnist.data, fmnist.target, n_samples=samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarized_scorer(metric, **kwargs):\n",
    "    lb = LabelBinarizer()\n",
    "    def score(y_test, y_pred, metric=metric, lb=lb, kwargs=kwargs):\n",
    "        lb.fit(y_test)\n",
    "        y_test = lb.transform(y_test)\n",
    "        y_pred = lb.transform(y_pred)\n",
    "        return metric(y_test, y_pred, **kwargs)\n",
    "    return make_scorer(score)\n",
    "\n",
    "def mk_test(clf, name):\n",
    "    def run_test(X, Y, clf=clf, name=name):\n",
    "        scoring = {\n",
    "            \"accuracy\":          binarized_scorer(accuracy_score), \n",
    "            \"f1\":                binarized_scorer(f1_score, average='macro'), \n",
    "            \"neg_log_loss\":      binarized_scorer(log_loss), \n",
    "            \"precision\":         binarized_scorer(precision_score, average='macro'), \n",
    "            \"recall\":            binarized_scorer(recall_score, average='macro'), \n",
    "            \"roc_auc\":           binarized_scorer(roc_auc_score, average='macro'),\n",
    "            # to je pole pod Precision-Recall, albo jakaś średnia. nie wiem.\n",
    "            \"average_precision\": binarized_scorer(average_precision_score, average='macro') \n",
    "        }\n",
    "        scores = cross_validate(clf, X, Y, cv=4, n_jobs=8, scoring=scoring)\n",
    "        return scores\n",
    "    return run_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mk_adaboost(depth=5, n=100, seed=1):\n",
    "    return AdaBoostClassifier(\n",
    "        base_estimator=DecisionTreeClassifier(max_depth=depth),\n",
    "        n_estimators=n,\n",
    "        random_state=seed)\n",
    "\n",
    "def mk_knn():\n",
    "    return KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([123.0119493 , 123.00694561, 122.40339684, 124.1129477 ]),\n",
       " 'score_time': array([0.43439364, 0.42738676, 0.41037226, 0.37333918]),\n",
       " 'test_accuracy': array([0.84857143, 0.85257143, 0.84114286, 0.86171429]),\n",
       " 'test_f1': array([0.84910824, 0.85383553, 0.84183597, 0.86415286]),\n",
       " 'test_neg_log_loss': array([5.23015757, 5.09200246, 5.48673134, 4.77621936]),\n",
       " 'test_precision': array([0.84986438, 0.85522527, 0.8426891 , 0.86592101]),\n",
       " 'test_recall': array([0.84937377, 0.85355064, 0.8419653 , 0.86298085]),\n",
       " 'test_roc_auc': array([0.91626236, 0.9185702 , 0.91214405, 0.92379401]),\n",
       " 'test_average_precision': array([0.75151053, 0.75900108, 0.73946241, 0.77189013])}"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = mk_test(mk_adaboost(depth=10), \"AdaBoost\")\n",
    "test(*mk_dataset(0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
