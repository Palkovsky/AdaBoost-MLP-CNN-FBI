{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, accuracy_score, plot_roc_curve,\\\n",
    "                             precision_recall_curve, plot_precision_recall_curve, f1_score, average_precision_score,\\\n",
    "                             hinge_loss, precision_score, recall_score, classification_report\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate\n",
    "from sklearn.metrics import make_scorer, accuracy_score, average_precision_score, f1_score,\\\n",
    "                            log_loss, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize, LabelBinarizer, LabelEncoder, OneHotEncoder\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.utils import resample\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmnist = fetch_openml(\"Fashion-MNIST\", data_home=\"./fmnist\", cache=True)\n",
    "classes = [str(x) for x in range(0, 10)]\n",
    "num_classes = len(classes)\n",
    "\n",
    "def mk_dataset(total, fmnist=fmnist, classes=classes):\n",
    "    samples = int(fmnist.data.shape[0]*total)\n",
    "    return resample(fmnist.data, fmnist.target, n_samples=samples)\n",
    "\n",
    "def plot_imgs(x, y, w=28, h=28):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    for i in range(min(25, x.shape[0])):\n",
    "        plt.subplot(5,5,i+1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        img = x[i]\n",
    "        img = img.reshape((w, h))\n",
    "        plt.imshow(img)\n",
    "        plt.xlabel(y[i])\n",
    "    plt.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarized_scorer(metric, **kwargs):\n",
    "    lb = LabelBinarizer()\n",
    "    def score(y_test, y_pred, metric=metric, lb=lb, kwargs=kwargs):\n",
    "        lb.fit(y_test)\n",
    "        y_test = lb.transform(y_test)\n",
    "        y_pred = lb.transform(y_pred)\n",
    "        return metric(y_test, y_pred, **kwargs)\n",
    "    return make_scorer(score)\n",
    "\n",
    "def mk_test(clf, name, gpu=False):\n",
    "    def run_test(X, Y, clf=clf, name=name):\n",
    "        scoring = {\n",
    "            \"accuracy\":     binarized_scorer(accuracy_score), \n",
    "            \"f1_score\":     binarized_scorer(f1_score, average='macro'), \n",
    "            \"log_loss\":     binarized_scorer(log_loss), \n",
    "            \"precision\":    binarized_scorer(precision_score, average='macro'), \n",
    "            \"recall\":       binarized_scorer(recall_score, average='macro'), \n",
    "            \"roc_auc\":      binarized_scorer(roc_auc_score, average='macro'),\n",
    "            # to je pole pod Precision-Recall, albo jakaś średnia. nie wiem.\n",
    "            \"prec_rec_auc\": binarized_scorer(average_precision_score, average='macro') \n",
    "        }\n",
    "        n_jobs = None if gpu else 8\n",
    "        scores = cross_validate(clf, X, Y, cv=5, n_jobs=n_jobs, scoring=scoring)\n",
    "        del scores['fit_time']\n",
    "        del scores['score_time']\n",
    "        keys = list(scores.keys())\n",
    "        for key in keys:\n",
    "            scores[key.replace('test_', '')] = [np.mean(scores.pop(key))]\n",
    "        df = pd.DataFrame.from_dict(scores)\n",
    "        df.insert(loc=0, column='Name', value=name)\n",
    "        return df\n",
    "    return run_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mk_adaboost(depth=5, n=100, seed=1):\n",
    "    return AdaBoostClassifier(\n",
    "        base_estimator=DecisionTreeClassifier(max_depth=depth),\n",
    "        n_estimators=n,\n",
    "        random_state=seed)\n",
    "\n",
    "class MyLittleKerasClassifier(KerasClassifier):\n",
    "    def predict(self, X):\n",
    "        y_pred = KerasClassifier.predict(self, X)\n",
    "        return to_categorical(y_pred, num_classes)\n",
    "\n",
    "def mk_mlp(epochs=10):\n",
    "    def build():\n",
    "        model = Sequential()\n",
    "        # starannie dobrane wartosci, wiem co robie\n",
    "        model.add(Dense(256, activation='relu', input_shape=(28*28,)))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(512, activation='relu'))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(512, activation='relu'))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(512, activation='relu'))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(256, activation='relu'))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(num_classes, activation='softmax'))\n",
    "        model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        return model\n",
    "    return MyLittleKerasClassifier(build_fn=build, epochs=epochs)\n",
    "\n",
    "def mk_cnn(epochs=10):\n",
    "    def build():\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(filters=32, kernel_size=(3, 3), input_shape=(28,28, 1), activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Conv2D(32, kernel_size = 5, strides=2, padding='same', activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.4))\n",
    "    \n",
    "        model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Conv2D(64, kernel_size = 5, strides=2, padding='same', activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.4))\n",
    "    \n",
    "        model.add(Conv2D(128, kernel_size = 4, activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Flatten())\n",
    "        model.add(Dropout(0.4))\n",
    "        model.add(Dense(10, activation='softmax'))\n",
    "        model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        return model\n",
    "    return MyLittleKerasClassifier(build_fn=build, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_cnn(data_sz, duration):\n",
    "    name = 'CNN | {}% of data'.format(data_sz*100.0)\n",
    "    x, y = mk_dataset(data_sz)\n",
    "    y = to_categorical(y, num_classes)\n",
    "    x /= 255.0\n",
    "    x = x.reshape((x.shape[0], 28, 28, 1))\n",
    "    return mk_test(mk_cnn(), name, gpu=True)(x, y)\n",
    "\n",
    "def test_mlp(data_sz, duration):\n",
    "    name = 'MLP | {}% of data'.format(data_sz*100.0)\n",
    "    x, y = mk_dataset(data_sz)\n",
    "    y = to_categorical(y, num_classes)\n",
    "    x /= 255.0\n",
    "    return mk_test(mk_mlp(), name, gpu=True)(x, y)\n",
    "\n",
    "def test_adaboost(data_sz, duration):\n",
    "    name = 'AdaBoost | {}% of data'.format(data_sz*100.0)\n",
    "    return mk_test(mk_adaboost(), name)(*mk_dataset(data_sz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5600/5600 [==============================] - 2s 334us/step - loss: 0.1625 - accuracy: 0.9354\n",
      "Epoch 2/10\n",
      "5600/5600 [==============================] - 1s 166us/step - loss: 0.1141 - accuracy: 0.9537\n",
      "Epoch 3/10\n",
      "5600/5600 [==============================] - 1s 165us/step - loss: 0.1012 - accuracy: 0.9592\n",
      "Epoch 4/10\n",
      "5600/5600 [==============================] - 1s 160us/step - loss: 0.0951 - accuracy: 0.9604\n",
      "Epoch 5/10\n",
      "5600/5600 [==============================] - 1s 175us/step - loss: 0.0880 - accuracy: 0.9640\n",
      "Epoch 6/10\n",
      "5600/5600 [==============================] - 1s 169us/step - loss: 0.0891 - accuracy: 0.9644\n",
      "Epoch 7/10\n",
      "5600/5600 [==============================] - 1s 173us/step - loss: 0.0824 - accuracy: 0.9666\n",
      "Epoch 8/10\n",
      "5600/5600 [==============================] - 1s 161us/step - loss: 0.0764 - accuracy: 0.9685\n",
      "Epoch 9/10\n",
      "5600/5600 [==============================] - 1s 156us/step - loss: 0.0750 - accuracy: 0.9691\n",
      "Epoch 10/10\n",
      "5600/5600 [==============================] - 1s 158us/step - loss: 0.0734 - accuracy: 0.9700\n",
      "Epoch 1/10\n",
      "5600/5600 [==============================] - 3s 521us/step - loss: 0.1663 - accuracy: 0.9332\n",
      "Epoch 2/10\n",
      "5600/5600 [==============================] - 2s 352us/step - loss: 0.1161 - accuracy: 0.9534\n",
      "Epoch 3/10\n",
      "5600/5600 [==============================] - 2s 350us/step - loss: 0.1050 - accuracy: 0.9571\n",
      "Epoch 4/10\n",
      "5600/5600 [==============================] - 2s 340us/step - loss: 0.0963 - accuracy: 0.9611\n",
      "Epoch 5/10\n",
      "5600/5600 [==============================] - 2s 358us/step - loss: 0.0892 - accuracy: 0.9642\n",
      "Epoch 6/10\n",
      "5600/5600 [==============================] - 2s 345us/step - loss: 0.0851 - accuracy: 0.9657\n",
      "Epoch 7/10\n",
      "5600/5600 [==============================] - 2s 346us/step - loss: 0.0843 - accuracy: 0.9660\n",
      "Epoch 8/10\n",
      "5600/5600 [==============================] - 2s 378us/step - loss: 0.0811 - accuracy: 0.9676\n",
      "Epoch 9/10\n",
      "5600/5600 [==============================] - 2s 376us/step - loss: 0.0791 - accuracy: 0.9683\n",
      "Epoch 10/10\n",
      "5600/5600 [==============================] - 2s 349us/step - loss: 0.0747 - accuracy: 0.9698\n",
      "Epoch 1/10\n",
      "5600/5600 [==============================] - 4s 641us/step - loss: 0.1620 - accuracy: 0.9349\n",
      "Epoch 2/10\n",
      "5600/5600 [==============================] - 3s 472us/step - loss: 0.1111 - accuracy: 0.9556\n",
      "Epoch 3/10\n",
      "5600/5600 [==============================] - 3s 473us/step - loss: 0.1002 - accuracy: 0.9593\n",
      "Epoch 4/10\n",
      "5600/5600 [==============================] - 3s 480us/step - loss: 0.0950 - accuracy: 0.9618\n",
      "Epoch 5/10\n",
      "5600/5600 [==============================] - 3s 478us/step - loss: 0.0914 - accuracy: 0.9630\n",
      "Epoch 6/10\n",
      "5600/5600 [==============================] - 3s 470us/step - loss: 0.0861 - accuracy: 0.9661\n",
      "Epoch 7/10\n",
      "5600/5600 [==============================] - 3s 459us/step - loss: 0.0808 - accuracy: 0.9680\n",
      "Epoch 8/10\n",
      "5600/5600 [==============================] - 3s 460us/step - loss: 0.0764 - accuracy: 0.9686\n",
      "Epoch 9/10\n",
      "5600/5600 [==============================] - 3s 460us/step - loss: 0.0739 - accuracy: 0.9702\n",
      "Epoch 10/10\n",
      "5600/5600 [==============================] - 3s 464us/step - loss: 0.0724 - accuracy: 0.9711\n",
      "Epoch 1/10\n",
      "5600/5600 [==============================] - 3s 562us/step - loss: 0.1584 - accuracy: 0.9379\n",
      "Epoch 2/10\n",
      "5600/5600 [==============================] - 2s 388us/step - loss: 0.1119 - accuracy: 0.9546\n",
      "Epoch 3/10\n",
      "5600/5600 [==============================] - 2s 380us/step - loss: 0.1018 - accuracy: 0.9592\n",
      "Epoch 4/10\n",
      "5600/5600 [==============================] - 2s 385us/step - loss: 0.0946 - accuracy: 0.9622\n",
      "Epoch 5/10\n",
      "5600/5600 [==============================] - 2s 379us/step - loss: 0.0880 - accuracy: 0.9644\n",
      "Epoch 6/10\n",
      "5600/5600 [==============================] - 2s 385us/step - loss: 0.0847 - accuracy: 0.9655\n",
      "Epoch 7/10\n",
      "5600/5600 [==============================] - 2s 381us/step - loss: 0.0836 - accuracy: 0.9663\n",
      "Epoch 8/10\n",
      "5600/5600 [==============================] - 2s 377us/step - loss: 0.0782 - accuracy: 0.9675\n",
      "Epoch 9/10\n",
      "5600/5600 [==============================] - 2s 382us/step - loss: 0.0780 - accuracy: 0.9680\n",
      "Epoch 10/10\n",
      "5600/5600 [==============================] - 2s 383us/step - loss: 0.0734 - accuracy: 0.9707\n",
      "Epoch 1/10\n",
      "5600/5600 [==============================] - 2s 418us/step - loss: 0.1652 - accuracy: 0.9351\n",
      "Epoch 2/10\n",
      "5600/5600 [==============================] - 1s 231us/step - loss: 0.1135 - accuracy: 0.9541\n",
      "Epoch 3/10\n",
      "5600/5600 [==============================] - 1s 230us/step - loss: 0.1022 - accuracy: 0.9581\n",
      "Epoch 4/10\n",
      "5600/5600 [==============================] - 1s 235us/step - loss: 0.0932 - accuracy: 0.9619\n",
      "Epoch 5/10\n",
      "5600/5600 [==============================] - 1s 240us/step - loss: 0.0910 - accuracy: 0.9629\n",
      "Epoch 6/10\n",
      "5600/5600 [==============================] - 1s 252us/step - loss: 0.0848 - accuracy: 0.9664\n",
      "Epoch 7/10\n",
      "5600/5600 [==============================] - 1s 237us/step - loss: 0.0789 - accuracy: 0.9678\n",
      "Epoch 8/10\n",
      "5600/5600 [==============================] - 1s 246us/step - loss: 0.0789 - accuracy: 0.9687\n",
      "Epoch 9/10\n",
      "5600/5600 [==============================] - 1s 255us/step - loss: 0.0771 - accuracy: 0.9678\n",
      "Epoch 10/10\n",
      "5600/5600 [==============================] - 1s 241us/step - loss: 0.0759 - accuracy: 0.9698\n",
      "Epoch 1/10\n",
      "28000/28000 [==============================] - 6s 216us/step - loss: 0.1186 - accuracy: 0.9526\n",
      "Epoch 2/10\n",
      "28000/28000 [==============================] - 5s 178us/step - loss: 0.0870 - accuracy: 0.9657\n",
      "Epoch 3/10\n",
      "28000/28000 [==============================] - 5s 177us/step - loss: 0.0807 - accuracy: 0.9684\n",
      "Epoch 4/10\n",
      "28000/28000 [==============================] - 5s 176us/step - loss: 0.0759 - accuracy: 0.9702\n",
      "Epoch 5/10\n",
      "28000/28000 [==============================] - 5s 174us/step - loss: 0.0727 - accuracy: 0.9714\n",
      "Epoch 6/10\n",
      "28000/28000 [==============================] - 5s 176us/step - loss: 0.0694 - accuracy: 0.9720\n",
      "Epoch 7/10\n",
      "28000/28000 [==============================] - 5s 172us/step - loss: 0.0684 - accuracy: 0.9729\n",
      "Epoch 8/10\n",
      "28000/28000 [==============================] - 5s 172us/step - loss: 0.0670 - accuracy: 0.9736\n",
      "Epoch 9/10\n",
      "28000/28000 [==============================] - 5s 180us/step - loss: 0.0647 - accuracy: 0.9743\n",
      "Epoch 10/10\n",
      "28000/28000 [==============================] - 5s 182us/step - loss: 0.0634 - accuracy: 0.9750\n",
      "Epoch 1/10\n",
      "28000/28000 [==============================] - 6s 216us/step - loss: 0.1149 - accuracy: 0.9546\n",
      "Epoch 2/10\n",
      "28000/28000 [==============================] - 5s 176us/step - loss: 0.0863 - accuracy: 0.9662\n",
      "Epoch 3/10\n",
      "28000/28000 [==============================] - 5s 173us/step - loss: 0.0801 - accuracy: 0.9686\n",
      "Epoch 4/10\n",
      "28000/28000 [==============================] - 5s 178us/step - loss: 0.0758 - accuracy: 0.9704\n",
      "Epoch 5/10\n",
      "28000/28000 [==============================] - 5s 177us/step - loss: 0.0723 - accuracy: 0.9719\n",
      "Epoch 6/10\n",
      "28000/28000 [==============================] - 5s 172us/step - loss: 0.0697 - accuracy: 0.9726\n",
      "Epoch 7/10\n",
      "28000/28000 [==============================] - 5s 175us/step - loss: 0.0679 - accuracy: 0.9733\n",
      "Epoch 8/10\n",
      "28000/28000 [==============================] - 5s 171us/step - loss: 0.0664 - accuracy: 0.9741\n",
      "Epoch 9/10\n",
      "28000/28000 [==============================] - 5s 170us/step - loss: 0.0652 - accuracy: 0.9746\n",
      "Epoch 10/10\n",
      "28000/28000 [==============================] - 5s 179us/step - loss: 0.0633 - accuracy: 0.9753\n",
      "Epoch 1/10\n",
      "28000/28000 [==============================] - 6s 222us/step - loss: 0.1145 - accuracy: 0.9544\n",
      "Epoch 2/10\n",
      "28000/28000 [==============================] - 5s 175us/step - loss: 0.0866 - accuracy: 0.9659\n",
      "Epoch 3/10\n",
      "28000/28000 [==============================] - 6s 198us/step - loss: 0.0792 - accuracy: 0.9685\n",
      "Epoch 4/10\n",
      "28000/28000 [==============================] - 5s 184us/step - loss: 0.0755 - accuracy: 0.9704\n",
      "Epoch 5/10\n",
      "28000/28000 [==============================] - 5s 180us/step - loss: 0.0723 - accuracy: 0.9715\n",
      "Epoch 6/10\n",
      "28000/28000 [==============================] - 5s 179us/step - loss: 0.0692 - accuracy: 0.9727\n",
      "Epoch 7/10\n",
      "28000/28000 [==============================] - 5s 182us/step - loss: 0.0677 - accuracy: 0.9731\n",
      "Epoch 8/10\n",
      "28000/28000 [==============================] - 5s 180us/step - loss: 0.0658 - accuracy: 0.9743\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28000/28000 [==============================] - 5s 176us/step - loss: 0.0651 - accuracy: 0.9744\n",
      "Epoch 10/10\n",
      "28000/28000 [==============================] - 5s 179us/step - loss: 0.0629 - accuracy: 0.9755\n",
      "Epoch 1/10\n",
      "28000/28000 [==============================] - 6s 220us/step - loss: 0.1165 - accuracy: 0.9533\n",
      "Epoch 2/10\n",
      "28000/28000 [==============================] - 5s 180us/step - loss: 0.0865 - accuracy: 0.9661\n",
      "Epoch 3/10\n",
      "28000/28000 [==============================] - 5s 180us/step - loss: 0.0790 - accuracy: 0.9689\n",
      "Epoch 4/10\n",
      "28000/28000 [==============================] - 5s 184us/step - loss: 0.0754 - accuracy: 0.9708\n",
      "Epoch 5/10\n",
      "28000/28000 [==============================] - 5s 180us/step - loss: 0.0729 - accuracy: 0.9720\n",
      "Epoch 6/10\n",
      "28000/28000 [==============================] - 5s 182us/step - loss: 0.0695 - accuracy: 0.9726\n",
      "Epoch 7/10\n",
      "28000/28000 [==============================] - 5s 183us/step - loss: 0.0671 - accuracy: 0.9736\n",
      "Epoch 8/10\n",
      "28000/28000 [==============================] - 5s 179us/step - loss: 0.0654 - accuracy: 0.9744\n",
      "Epoch 9/10\n",
      "28000/28000 [==============================] - 5s 180us/step - loss: 0.0641 - accuracy: 0.9751\n",
      "Epoch 10/10\n",
      "28000/28000 [==============================] - 5s 179us/step - loss: 0.0618 - accuracy: 0.9757\n",
      "Epoch 1/10\n",
      "28000/28000 [==============================] - 7s 234us/step - loss: 0.1150 - accuracy: 0.9545\n",
      "Epoch 2/10\n",
      "28000/28000 [==============================] - 5s 187us/step - loss: 0.0868 - accuracy: 0.9657\n",
      "Epoch 3/10\n",
      "28000/28000 [==============================] - 5s 183us/step - loss: 0.0802 - accuracy: 0.9688\n",
      "Epoch 4/10\n",
      "28000/28000 [==============================] - 5s 188us/step - loss: 0.0746 - accuracy: 0.9709\n",
      "Epoch 5/10\n",
      "28000/28000 [==============================] - 5s 184us/step - loss: 0.0726 - accuracy: 0.9715\n",
      "Epoch 6/10\n",
      "28000/28000 [==============================] - 5s 184us/step - loss: 0.0698 - accuracy: 0.9729\n",
      "Epoch 7/10\n",
      "28000/28000 [==============================] - 5s 185us/step - loss: 0.0678 - accuracy: 0.9737\n",
      "Epoch 8/10\n",
      "28000/28000 [==============================] - 5s 184us/step - loss: 0.0672 - accuracy: 0.9739\n",
      "Epoch 9/10\n",
      "28000/28000 [==============================] - 5s 186us/step - loss: 0.0657 - accuracy: 0.9743\n",
      "Epoch 10/10\n",
      "28000/28000 [==============================] - 5s 186us/step - loss: 0.0636 - accuracy: 0.9753\n",
      "Epoch 1/10\n",
      "56000/56000 [==============================] - 11s 204us/step - loss: 0.1020 - accuracy: 0.9595\n",
      "Epoch 2/10\n",
      "56000/56000 [==============================] - 10s 185us/step - loss: 0.0799 - accuracy: 0.9682\n",
      "Epoch 3/10\n",
      "56000/56000 [==============================] - 10s 182us/step - loss: 0.0741 - accuracy: 0.9709\n",
      "Epoch 4/10\n",
      "56000/56000 [==============================] - 10s 183us/step - loss: 0.0698 - accuracy: 0.9729\n",
      "Epoch 5/10\n",
      "56000/56000 [==============================] - 10s 181us/step - loss: 0.0668 - accuracy: 0.9738\n",
      "Epoch 6/10\n",
      "56000/56000 [==============================] - 10s 180us/step - loss: 0.0646 - accuracy: 0.9750\n",
      "Epoch 7/10\n",
      "56000/56000 [==============================] - 12s 207us/step - loss: 0.0619 - accuracy: 0.9761\n",
      "Epoch 8/10\n",
      "56000/56000 [==============================] - 11s 203us/step - loss: 0.0613 - accuracy: 0.9763\n",
      "Epoch 9/10\n",
      "56000/56000 [==============================] - 11s 202us/step - loss: 0.0592 - accuracy: 0.9770\n",
      "Epoch 10/10\n",
      "56000/56000 [==============================] - 11s 202us/step - loss: 0.0583 - accuracy: 0.9773\n",
      "Epoch 1/10\n",
      "56000/56000 [==============================] - 13s 225us/step - loss: 0.1015 - accuracy: 0.9596\n",
      "Epoch 2/10\n",
      "56000/56000 [==============================] - 11s 198us/step - loss: 0.0799 - accuracy: 0.9684\n",
      "Epoch 3/10\n",
      "56000/56000 [==============================] - 11s 197us/step - loss: 0.0737 - accuracy: 0.9711\n",
      "Epoch 4/10\n",
      "56000/56000 [==============================] - 11s 196us/step - loss: 0.0695 - accuracy: 0.9727\n",
      "Epoch 5/10\n",
      "56000/56000 [==============================] - 11s 198us/step - loss: 0.0664 - accuracy: 0.9739\n",
      "Epoch 6/10\n",
      "56000/56000 [==============================] - 11s 198us/step - loss: 0.0646 - accuracy: 0.9748\n",
      "Epoch 7/10\n",
      "56000/56000 [==============================] - 11s 197us/step - loss: 0.0625 - accuracy: 0.9753\n",
      "Epoch 8/10\n",
      "56000/56000 [==============================] - 11s 196us/step - loss: 0.0611 - accuracy: 0.9764\n",
      "Epoch 9/10\n",
      "56000/56000 [==============================] - 11s 196us/step - loss: 0.0597 - accuracy: 0.9771\n",
      "Epoch 10/10\n",
      "56000/56000 [==============================] - 11s 193us/step - loss: 0.0585 - accuracy: 0.9772\n",
      "Epoch 1/10\n",
      "56000/56000 [==============================] - 12s 217us/step - loss: 0.1022 - accuracy: 0.9596\n",
      "Epoch 2/10\n",
      "56000/56000 [==============================] - 11s 204us/step - loss: 0.0801 - accuracy: 0.9686\n",
      "Epoch 3/10\n",
      "56000/56000 [==============================] - 11s 203us/step - loss: 0.0740 - accuracy: 0.9712\n",
      "Epoch 4/10\n",
      "56000/56000 [==============================] - 11s 203us/step - loss: 0.0700 - accuracy: 0.9727\n",
      "Epoch 5/10\n",
      "56000/56000 [==============================] - 11s 201us/step - loss: 0.0668 - accuracy: 0.9738\n",
      "Epoch 6/10\n",
      "56000/56000 [==============================] - 11s 200us/step - loss: 0.0647 - accuracy: 0.9749\n",
      "Epoch 7/10\n",
      "56000/56000 [==============================] - 11s 201us/step - loss: 0.0625 - accuracy: 0.9756\n",
      "Epoch 8/10\n",
      "56000/56000 [==============================] - 11s 203us/step - loss: 0.0608 - accuracy: 0.9760\n",
      "Epoch 9/10\n",
      "56000/56000 [==============================] - 11s 205us/step - loss: 0.0608 - accuracy: 0.9764\n",
      "Epoch 10/10\n",
      "56000/56000 [==============================] - 12s 206us/step - loss: 0.0592 - accuracy: 0.9769\n",
      "Epoch 1/10\n",
      "56000/56000 [==============================] - 13s 229us/step - loss: 0.1020 - accuracy: 0.9599\n",
      "Epoch 2/10\n",
      "56000/56000 [==============================] - 12s 206us/step - loss: 0.0789 - accuracy: 0.9689\n",
      "Epoch 3/10\n",
      "56000/56000 [==============================] - 12s 206us/step - loss: 0.0737 - accuracy: 0.9711\n",
      "Epoch 4/10\n",
      "56000/56000 [==============================] - 11s 203us/step - loss: 0.0691 - accuracy: 0.9733\n",
      "Epoch 5/10\n",
      "56000/56000 [==============================] - 11s 205us/step - loss: 0.0674 - accuracy: 0.9737\n",
      "Epoch 6/10\n",
      "56000/56000 [==============================] - 11s 196us/step - loss: 0.0643 - accuracy: 0.9751\n",
      "Epoch 7/10\n",
      "56000/56000 [==============================] - 10s 184us/step - loss: 0.0631 - accuracy: 0.9755\n",
      "Epoch 8/10\n",
      "56000/56000 [==============================] - 10s 187us/step - loss: 0.0618 - accuracy: 0.9762\n",
      "Epoch 9/10\n",
      "56000/56000 [==============================] - 11s 188us/step - loss: 0.0598 - accuracy: 0.9768\n",
      "Epoch 10/10\n",
      "56000/56000 [==============================] - 10s 187us/step - loss: 0.0586 - accuracy: 0.9772\n",
      "Epoch 1/10\n",
      "56000/56000 [==============================] - 12s 211us/step - loss: 0.1024 - accuracy: 0.9597\n",
      "Epoch 2/10\n",
      "56000/56000 [==============================] - 11s 189us/step - loss: 0.0794 - accuracy: 0.9690\n",
      "Epoch 3/10\n",
      "56000/56000 [==============================] - 11s 188us/step - loss: 0.0745 - accuracy: 0.9711\n",
      "Epoch 4/10\n",
      "56000/56000 [==============================] - 11s 192us/step - loss: 0.0698 - accuracy: 0.9730\n",
      "Epoch 5/10\n",
      "56000/56000 [==============================] - 11s 190us/step - loss: 0.0671 - accuracy: 0.9738\n",
      "Epoch 6/10\n",
      "56000/56000 [==============================] - 11s 189us/step - loss: 0.0647 - accuracy: 0.9747\n",
      "Epoch 7/10\n",
      "56000/56000 [==============================] - 11s 189us/step - loss: 0.0638 - accuracy: 0.9755\n",
      "Epoch 8/10\n",
      "56000/56000 [==============================] - 11s 189us/step - loss: 0.0616 - accuracy: 0.9764\n",
      "Epoch 9/10\n",
      "56000/56000 [==============================] - 10s 187us/step - loss: 0.0606 - accuracy: 0.9767\n",
      "Epoch 10/10\n",
      "56000/56000 [==============================] - 11s 189us/step - loss: 0.0595 - accuracy: 0.9769\n",
      "Epoch 1/10\n",
      "5600/5600 [==============================] - 4s 658us/step - loss: 0.1694 - accuracy: 0.9378\n",
      "Epoch 2/10\n",
      "5600/5600 [==============================] - 2s 365us/step - loss: 0.1158 - accuracy: 0.9540\n",
      "Epoch 3/10\n",
      "5600/5600 [==============================] - 2s 379us/step - loss: 0.0966 - accuracy: 0.9605\n",
      "Epoch 4/10\n",
      "5600/5600 [==============================] - 2s 377us/step - loss: 0.0864 - accuracy: 0.9647\n",
      "Epoch 5/10\n",
      "5600/5600 [==============================] - 2s 399us/step - loss: 0.0775 - accuracy: 0.9683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10\n",
      "5600/5600 [==============================] - 2s 427us/step - loss: 0.0731 - accuracy: 0.9712\n",
      "Epoch 7/10\n",
      "5600/5600 [==============================] - 2s 371us/step - loss: 0.0703 - accuracy: 0.9719\n",
      "Epoch 8/10\n",
      "5600/5600 [==============================] - 2s 358us/step - loss: 0.0624 - accuracy: 0.9755\n",
      "Epoch 9/10\n",
      "5600/5600 [==============================] - 2s 355us/step - loss: 0.0583 - accuracy: 0.9772\n",
      "Epoch 10/10\n",
      "5600/5600 [==============================] - 2s 358us/step - loss: 0.0564 - accuracy: 0.9779\n",
      "Epoch 1/10\n",
      "5600/5600 [==============================] - 4s 648us/step - loss: 0.1663 - accuracy: 0.9371\n",
      "Epoch 2/10\n",
      "5600/5600 [==============================] - 2s 352us/step - loss: 0.1132 - accuracy: 0.9539\n",
      "Epoch 3/10\n",
      "5600/5600 [==============================] - 2s 355us/step - loss: 0.0958 - accuracy: 0.9619\n",
      "Epoch 4/10\n",
      "5600/5600 [==============================] - 2s 361us/step - loss: 0.0902 - accuracy: 0.9644\n",
      "Epoch 5/10\n",
      "5600/5600 [==============================] - 2s 353us/step - loss: 0.0781 - accuracy: 0.9684\n",
      "Epoch 6/10\n",
      "5600/5600 [==============================] - 2s 353us/step - loss: 0.0722 - accuracy: 0.9714\n",
      "Epoch 7/10\n",
      "5600/5600 [==============================] - 2s 354us/step - loss: 0.0694 - accuracy: 0.9720\n",
      "Epoch 8/10\n",
      "5600/5600 [==============================] - 2s 353us/step - loss: 0.0658 - accuracy: 0.9735\n",
      "Epoch 9/10\n",
      "5600/5600 [==============================] - 2s 352us/step - loss: 0.0612 - accuracy: 0.9760\n",
      "Epoch 10/10\n",
      "5600/5600 [==============================] - 2s 352us/step - loss: 0.0569 - accuracy: 0.9780\n",
      "Epoch 1/10\n",
      "5600/5600 [==============================] - 4s 649us/step - loss: 0.1753 - accuracy: 0.9353\n",
      "Epoch 2/10\n",
      "5600/5600 [==============================] - 2s 364us/step - loss: 0.1131 - accuracy: 0.9546\n",
      "Epoch 3/10\n",
      "5600/5600 [==============================] - 2s 356us/step - loss: 0.0994 - accuracy: 0.9596\n",
      "Epoch 4/10\n",
      "5600/5600 [==============================] - 2s 355us/step - loss: 0.0883 - accuracy: 0.9646\n",
      "Epoch 5/10\n",
      "5600/5600 [==============================] - 2s 358us/step - loss: 0.0786 - accuracy: 0.9679\n",
      "Epoch 6/10\n",
      "5600/5600 [==============================] - 2s 357us/step - loss: 0.0704 - accuracy: 0.9727\n",
      "Epoch 7/10\n",
      "5600/5600 [==============================] - 2s 355us/step - loss: 0.0672 - accuracy: 0.9736\n",
      "Epoch 8/10\n",
      "5600/5600 [==============================] - 2s 354us/step - loss: 0.0613 - accuracy: 0.9756\n",
      "Epoch 9/10\n",
      "5600/5600 [==============================] - 2s 357us/step - loss: 0.0582 - accuracy: 0.9776\n",
      "Epoch 10/10\n",
      "5600/5600 [==============================] - 2s 366us/step - loss: 0.0562 - accuracy: 0.9774\n",
      "Epoch 1/10\n",
      "5600/5600 [==============================] - 4s 765us/step - loss: 0.1668 - accuracy: 0.9391\n",
      "Epoch 2/10\n",
      "5600/5600 [==============================] - 2s 394us/step - loss: 0.1136 - accuracy: 0.9554\n",
      "Epoch 3/10\n",
      "5600/5600 [==============================] - 2s 390us/step - loss: 0.0991 - accuracy: 0.9603\n",
      "Epoch 4/10\n",
      "5600/5600 [==============================] - 2s 396us/step - loss: 0.0909 - accuracy: 0.9637\n",
      "Epoch 5/10\n",
      "5600/5600 [==============================] - 2s 419us/step - loss: 0.0814 - accuracy: 0.9679\n",
      "Epoch 6/10\n",
      "5600/5600 [==============================] - 2s 389us/step - loss: 0.0745 - accuracy: 0.9702\n",
      "Epoch 7/10\n",
      "5600/5600 [==============================] - 2s 382us/step - loss: 0.0709 - accuracy: 0.9720\n",
      "Epoch 8/10\n",
      "5600/5600 [==============================] - 2s 422us/step - loss: 0.0661 - accuracy: 0.9747\n",
      "Epoch 9/10\n",
      "5600/5600 [==============================] - 2s 433us/step - loss: 0.0629 - accuracy: 0.9757\n",
      "Epoch 10/10\n",
      "5600/5600 [==============================] - 2s 408us/step - loss: 0.0586 - accuracy: 0.9779\n",
      "Epoch 1/10\n",
      "5600/5600 [==============================] - 4s 698us/step - loss: 0.1770 - accuracy: 0.9344\n",
      "Epoch 2/10\n",
      "5600/5600 [==============================] - 2s 381us/step - loss: 0.1151 - accuracy: 0.9543\n",
      "Epoch 3/10\n",
      "5600/5600 [==============================] - 2s 379us/step - loss: 0.0991 - accuracy: 0.9599\n",
      "Epoch 4/10\n",
      "5600/5600 [==============================] - 2s 384us/step - loss: 0.0874 - accuracy: 0.9645\n",
      "Epoch 5/10\n",
      "5600/5600 [==============================] - 2s 382us/step - loss: 0.0810 - accuracy: 0.9683\n",
      "Epoch 6/10\n",
      "5600/5600 [==============================] - 2s 387us/step - loss: 0.0754 - accuracy: 0.9702\n",
      "Epoch 7/10\n",
      "5600/5600 [==============================] - 2s 378us/step - loss: 0.0712 - accuracy: 0.9712\n",
      "Epoch 8/10\n",
      "5600/5600 [==============================] - 2s 375us/step - loss: 0.0662 - accuracy: 0.9740\n",
      "Epoch 9/10\n",
      "5600/5600 [==============================] - 2s 382us/step - loss: 0.0634 - accuracy: 0.9757\n",
      "Epoch 10/10\n",
      "5600/5600 [==============================] - 2s 377us/step - loss: 0.0607 - accuracy: 0.9752\n",
      "Epoch 1/10\n",
      "28000/28000 [==============================] - 13s 454us/step - loss: 0.1134 - accuracy: 0.9553\n",
      "Epoch 2/10\n",
      "28000/28000 [==============================] - 11s 391us/step - loss: 0.0747 - accuracy: 0.9709\n",
      "Epoch 3/10\n",
      "28000/28000 [==============================] - 11s 388us/step - loss: 0.0638 - accuracy: 0.9751\n",
      "Epoch 4/10\n",
      "28000/28000 [==============================] - 11s 391us/step - loss: 0.0581 - accuracy: 0.9773\n",
      "Epoch 5/10\n",
      "28000/28000 [==============================] - 11s 390us/step - loss: 0.0536 - accuracy: 0.9794\n",
      "Epoch 6/10\n",
      "28000/28000 [==============================] - 11s 389us/step - loss: 0.0494 - accuracy: 0.9808\n",
      "Epoch 7/10\n",
      "28000/28000 [==============================] - 11s 389us/step - loss: 0.0470 - accuracy: 0.9817\n",
      "Epoch 8/10\n",
      "28000/28000 [==============================] - 11s 389us/step - loss: 0.0432 - accuracy: 0.9836\n",
      "Epoch 9/10\n",
      "28000/28000 [==============================] - 11s 388us/step - loss: 0.0410 - accuracy: 0.9842\n",
      "Epoch 10/10\n",
      "28000/28000 [==============================] - 11s 385us/step - loss: 0.0390 - accuracy: 0.9849\n",
      "Epoch 1/10\n",
      "28000/28000 [==============================] - 13s 451us/step - loss: 0.1207 - accuracy: 0.9530\n",
      "Epoch 2/10\n",
      "28000/28000 [==============================] - 11s 383us/step - loss: 0.0772 - accuracy: 0.9695\n",
      "Epoch 3/10\n",
      "28000/28000 [==============================] - 11s 382us/step - loss: 0.0651 - accuracy: 0.9744\n",
      "Epoch 4/10\n",
      "28000/28000 [==============================] - 11s 384us/step - loss: 0.0597 - accuracy: 0.9767\n",
      "Epoch 5/10\n",
      "28000/28000 [==============================] - 11s 385us/step - loss: 0.0541 - accuracy: 0.9785\n",
      "Epoch 6/10\n",
      "28000/28000 [==============================] - 11s 382us/step - loss: 0.0511 - accuracy: 0.9800\n",
      "Epoch 7/10\n",
      "28000/28000 [==============================] - 12s 431us/step - loss: 0.0470 - accuracy: 0.9817\n",
      "Epoch 8/10\n",
      "28000/28000 [==============================] - 11s 399us/step - loss: 0.0447 - accuracy: 0.9830\n",
      "Epoch 9/10\n",
      "28000/28000 [==============================] - 11s 381us/step - loss: 0.0417 - accuracy: 0.9840\n",
      "Epoch 10/10\n",
      "28000/28000 [==============================] - 11s 376us/step - loss: 0.0399 - accuracy: 0.9848\n",
      "Epoch 1/10\n",
      "28000/28000 [==============================] - 12s 440us/step - loss: 0.1166 - accuracy: 0.9537\n",
      "Epoch 2/10\n",
      "28000/28000 [==============================] - 12s 414us/step - loss: 0.0765 - accuracy: 0.9700\n",
      "Epoch 3/10\n",
      "28000/28000 [==============================] - 11s 388us/step - loss: 0.0643 - accuracy: 0.9751\n",
      "Epoch 4/10\n",
      "28000/28000 [==============================] - 11s 388us/step - loss: 0.0582 - accuracy: 0.9773\n",
      "Epoch 5/10\n",
      "28000/28000 [==============================] - 11s 387us/step - loss: 0.0542 - accuracy: 0.9789\n",
      "Epoch 6/10\n",
      "28000/28000 [==============================] - 11s 386us/step - loss: 0.0510 - accuracy: 0.9801\n",
      "Epoch 7/10\n",
      "28000/28000 [==============================] - 11s 386us/step - loss: 0.0476 - accuracy: 0.9817\n",
      "Epoch 8/10\n",
      "28000/28000 [==============================] - 11s 386us/step - loss: 0.0440 - accuracy: 0.9832\n",
      "Epoch 9/10\n",
      "28000/28000 [==============================] - 11s 383us/step - loss: 0.0412 - accuracy: 0.9844\n",
      "Epoch 10/10\n",
      "28000/28000 [==============================] - 11s 387us/step - loss: 0.0396 - accuracy: 0.9846\n",
      "Epoch 1/10\n",
      "28000/28000 [==============================] - 13s 461us/step - loss: 0.1163 - accuracy: 0.9544\n",
      "Epoch 2/10\n",
      "28000/28000 [==============================] - 11s 392us/step - loss: 0.0768 - accuracy: 0.9697\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28000/28000 [==============================] - 11s 387us/step - loss: 0.0659 - accuracy: 0.9743\n",
      "Epoch 4/10\n",
      "28000/28000 [==============================] - 11s 391us/step - loss: 0.0591 - accuracy: 0.9770\n",
      "Epoch 5/10\n",
      "28000/28000 [==============================] - 11s 390us/step - loss: 0.0546 - accuracy: 0.9783\n",
      "Epoch 6/10\n",
      "28000/28000 [==============================] - 11s 388us/step - loss: 0.0508 - accuracy: 0.9799\n",
      "Epoch 7/10\n",
      "28000/28000 [==============================] - 11s 390us/step - loss: 0.0477 - accuracy: 0.9817\n",
      "Epoch 8/10\n",
      "28000/28000 [==============================] - 11s 390us/step - loss: 0.0441 - accuracy: 0.9830\n",
      "Epoch 9/10\n",
      "28000/28000 [==============================] - 11s 389us/step - loss: 0.0415 - accuracy: 0.9841\n",
      "Epoch 10/10\n",
      "28000/28000 [==============================] - 11s 390us/step - loss: 0.0400 - accuracy: 0.9846\n",
      "Epoch 1/10\n",
      "28000/28000 [==============================] - 14s 497us/step - loss: 0.1155 - accuracy: 0.9553\n",
      "Epoch 2/10\n",
      "28000/28000 [==============================] - 11s 408us/step - loss: 0.0756 - accuracy: 0.9703\n",
      "Epoch 3/10\n",
      "28000/28000 [==============================] - 12s 412us/step - loss: 0.0645 - accuracy: 0.9744\n",
      "Epoch 4/10\n",
      "28000/28000 [==============================] - 11s 406us/step - loss: 0.0575 - accuracy: 0.9774\n",
      "Epoch 5/10\n",
      "28000/28000 [==============================] - 11s 403us/step - loss: 0.0541 - accuracy: 0.9789\n",
      "Epoch 6/10\n",
      "28000/28000 [==============================] - 11s 402us/step - loss: 0.0493 - accuracy: 0.9807\n",
      "Epoch 7/10\n",
      "28000/28000 [==============================] - 11s 398us/step - loss: 0.0471 - accuracy: 0.9817\n",
      "Epoch 8/10\n",
      "28000/28000 [==============================] - 11s 398us/step - loss: 0.0448 - accuracy: 0.9825\n",
      "Epoch 9/10\n",
      "28000/28000 [==============================] - 11s 395us/step - loss: 0.0418 - accuracy: 0.9841\n",
      "Epoch 10/10\n",
      "28000/28000 [==============================] - 11s 394us/step - loss: 0.0395 - accuracy: 0.9848\n",
      "Epoch 1/10\n",
      "56000/56000 [==============================] - 25s 445us/step - loss: 0.0962 - accuracy: 0.9624\n",
      "Epoch 2/10\n",
      "56000/56000 [==============================] - 23s 407us/step - loss: 0.0624 - accuracy: 0.9758\n",
      "Epoch 3/10\n",
      "56000/56000 [==============================] - 23s 407us/step - loss: 0.0545 - accuracy: 0.9786\n",
      "Epoch 4/10\n",
      "56000/56000 [==============================] - 23s 409us/step - loss: 0.0487 - accuracy: 0.9810\n",
      "Epoch 5/10\n",
      "56000/56000 [==============================] - 23s 411us/step - loss: 0.0445 - accuracy: 0.9829\n",
      "Epoch 6/10\n",
      "56000/56000 [==============================] - 23s 410us/step - loss: 0.0410 - accuracy: 0.9843\n",
      "Epoch 7/10\n",
      "56000/56000 [==============================] - 23s 404us/step - loss: 0.0383 - accuracy: 0.9851\n",
      "Epoch 8/10\n",
      "56000/56000 [==============================] - 23s 405us/step - loss: 0.0360 - accuracy: 0.9860\n",
      "Epoch 9/10\n",
      "56000/56000 [==============================] - 23s 403us/step - loss: 0.0332 - accuracy: 0.9873\n",
      "Epoch 10/10\n",
      "56000/56000 [==============================] - 23s 403us/step - loss: 0.0318 - accuracy: 0.9877\n",
      "Epoch 1/10\n",
      "56000/56000 [==============================] - 25s 448us/step - loss: 0.0972 - accuracy: 0.9617\n",
      "Epoch 2/10\n",
      "56000/56000 [==============================] - 23s 410us/step - loss: 0.0640 - accuracy: 0.9751\n",
      "Epoch 3/10\n",
      "56000/56000 [==============================] - 24s 429us/step - loss: 0.0551 - accuracy: 0.9785\n",
      "Epoch 4/10\n",
      "56000/56000 [==============================] - 23s 414us/step - loss: 0.0494 - accuracy: 0.9810\n",
      "Epoch 5/10\n",
      "56000/56000 [==============================] - 23s 411us/step - loss: 0.0452 - accuracy: 0.9827\n",
      "Epoch 6/10\n",
      "56000/56000 [==============================] - 23s 413us/step - loss: 0.0412 - accuracy: 0.9841\n",
      "Epoch 7/10\n",
      "56000/56000 [==============================] - 23s 412us/step - loss: 0.0379 - accuracy: 0.9854\n",
      "Epoch 8/10\n",
      "56000/56000 [==============================] - 23s 412us/step - loss: 0.0360 - accuracy: 0.9863\n",
      "Epoch 9/10\n",
      "56000/56000 [==============================] - 23s 412us/step - loss: 0.0336 - accuracy: 0.9870\n",
      "Epoch 10/10\n",
      "56000/56000 [==============================] - 23s 413us/step - loss: 0.0317 - accuracy: 0.9879\n",
      "Epoch 1/10\n",
      "56000/56000 [==============================] - 26s 457us/step - loss: 0.0967 - accuracy: 0.9619\n",
      "Epoch 2/10\n",
      "56000/56000 [==============================] - 23s 418us/step - loss: 0.0632 - accuracy: 0.9751\n",
      "Epoch 3/10\n",
      "56000/56000 [==============================] - 23s 418us/step - loss: 0.0547 - accuracy: 0.9787\n",
      "Epoch 4/10\n",
      "56000/56000 [==============================] - 23s 418us/step - loss: 0.0495 - accuracy: 0.9808\n",
      "Epoch 5/10\n",
      "56000/56000 [==============================] - 23s 417us/step - loss: 0.0456 - accuracy: 0.9823\n",
      "Epoch 6/10\n",
      "56000/56000 [==============================] - 23s 418us/step - loss: 0.0414 - accuracy: 0.9840\n",
      "Epoch 7/10\n",
      "56000/56000 [==============================] - 23s 416us/step - loss: 0.0385 - accuracy: 0.9852\n",
      "Epoch 8/10\n",
      "56000/56000 [==============================] - 23s 418us/step - loss: 0.0361 - accuracy: 0.9861\n",
      "Epoch 9/10\n",
      "56000/56000 [==============================] - 23s 417us/step - loss: 0.0344 - accuracy: 0.9870\n",
      "Epoch 10/10\n",
      "56000/56000 [==============================] - 23s 417us/step - loss: 0.0319 - accuracy: 0.9879\n",
      "Epoch 1/10\n",
      "56000/56000 [==============================] - 26s 472us/step - loss: 0.0959 - accuracy: 0.9621\n",
      "Epoch 2/10\n",
      "56000/56000 [==============================] - 24s 428us/step - loss: 0.0633 - accuracy: 0.9751\n",
      "Epoch 3/10\n",
      "56000/56000 [==============================] - 24s 429us/step - loss: 0.0545 - accuracy: 0.9787\n",
      "Epoch 4/10\n",
      "56000/56000 [==============================] - 24s 431us/step - loss: 0.0487 - accuracy: 0.9809\n",
      "Epoch 5/10\n",
      "56000/56000 [==============================] - 24s 429us/step - loss: 0.0445 - accuracy: 0.9828\n",
      "Epoch 6/10\n",
      "56000/56000 [==============================] - 24s 428us/step - loss: 0.0415 - accuracy: 0.9841\n",
      "Epoch 7/10\n",
      "56000/56000 [==============================] - 24s 426us/step - loss: 0.0376 - accuracy: 0.9854\n",
      "Epoch 8/10\n",
      "56000/56000 [==============================] - 24s 426us/step - loss: 0.0360 - accuracy: 0.9861\n",
      "Epoch 9/10\n",
      "56000/56000 [==============================] - 24s 427us/step - loss: 0.0335 - accuracy: 0.9872\n",
      "Epoch 10/10\n",
      "56000/56000 [==============================] - 24s 425us/step - loss: 0.0315 - accuracy: 0.9880\n",
      "Epoch 1/10\n",
      "56000/56000 [==============================] - 27s 475us/step - loss: 0.0968 - accuracy: 0.9619\n",
      "Epoch 2/10\n",
      "56000/56000 [==============================] - 24s 428us/step - loss: 0.0646 - accuracy: 0.9746\n",
      "Epoch 3/10\n",
      "56000/56000 [==============================] - 24s 426us/step - loss: 0.0554 - accuracy: 0.9786\n",
      "Epoch 4/10\n",
      "56000/56000 [==============================] - 24s 428us/step - loss: 0.0487 - accuracy: 0.9809\n",
      "Epoch 5/10\n",
      "56000/56000 [==============================] - 24s 433us/step - loss: 0.0449 - accuracy: 0.9828\n",
      "Epoch 6/10\n",
      "56000/56000 [==============================] - 24s 432us/step - loss: 0.0414 - accuracy: 0.9841\n",
      "Epoch 7/10\n",
      "56000/56000 [==============================] - 24s 430us/step - loss: 0.0383 - accuracy: 0.9852\n",
      "Epoch 8/10\n",
      "56000/56000 [==============================] - 24s 431us/step - loss: 0.0362 - accuracy: 0.9862\n",
      "Epoch 9/10\n",
      "56000/56000 [==============================] - 24s 432us/step - loss: 0.0334 - accuracy: 0.9872\n",
      "Epoch 10/10\n",
      "56000/56000 [==============================] - 24s 429us/step - loss: 0.0312 - accuracy: 0.9881\n"
     ]
    }
   ],
   "source": [
    "tests = [method(data_sz, None) for method in [test_adaboost, test_mlp, test_cnn] for data_sz in [0.1, 0.5, 1.0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>log_loss</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>prec_rec_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AdaBoost | 10.0% of data</td>\n",
       "      <td>0.749000</td>\n",
       "      <td>0.751889</td>\n",
       "      <td>8.669233</td>\n",
       "      <td>0.760712</td>\n",
       "      <td>0.749163</td>\n",
       "      <td>0.860646</td>\n",
       "      <td>0.619367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AdaBoost | 50.0% of data</td>\n",
       "      <td>0.742371</td>\n",
       "      <td>0.743587</td>\n",
       "      <td>8.898176</td>\n",
       "      <td>0.747366</td>\n",
       "      <td>0.742739</td>\n",
       "      <td>0.857054</td>\n",
       "      <td>0.615169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AdaBoost | 100.0% of data</td>\n",
       "      <td>0.721543</td>\n",
       "      <td>0.720520</td>\n",
       "      <td>9.617569</td>\n",
       "      <td>0.722992</td>\n",
       "      <td>0.721553</td>\n",
       "      <td>0.845308</td>\n",
       "      <td>0.586956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLP | 10.0% of data</td>\n",
       "      <td>0.837286</td>\n",
       "      <td>0.834244</td>\n",
       "      <td>5.619952</td>\n",
       "      <td>0.841715</td>\n",
       "      <td>0.838094</td>\n",
       "      <td>0.910006</td>\n",
       "      <td>0.732207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLP | 50.0% of data</td>\n",
       "      <td>0.874686</td>\n",
       "      <td>0.873188</td>\n",
       "      <td>4.328202</td>\n",
       "      <td>0.876692</td>\n",
       "      <td>0.875419</td>\n",
       "      <td>0.930747</td>\n",
       "      <td>0.787478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLP | 100.0% of data</td>\n",
       "      <td>0.883429</td>\n",
       "      <td>0.881977</td>\n",
       "      <td>4.026235</td>\n",
       "      <td>0.886163</td>\n",
       "      <td>0.883997</td>\n",
       "      <td>0.935520</td>\n",
       "      <td>0.802150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CNN | 10.0% of data</td>\n",
       "      <td>0.867143</td>\n",
       "      <td>0.862843</td>\n",
       "      <td>4.588723</td>\n",
       "      <td>0.868083</td>\n",
       "      <td>0.864648</td>\n",
       "      <td>0.924962</td>\n",
       "      <td>0.773621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CNN | 50.0% of data</td>\n",
       "      <td>0.923371</td>\n",
       "      <td>0.923179</td>\n",
       "      <td>2.646657</td>\n",
       "      <td>0.924378</td>\n",
       "      <td>0.923170</td>\n",
       "      <td>0.957329</td>\n",
       "      <td>0.864555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CNN | 100.0% of data</td>\n",
       "      <td>0.941800</td>\n",
       "      <td>0.941464</td>\n",
       "      <td>2.010157</td>\n",
       "      <td>0.942539</td>\n",
       "      <td>0.941428</td>\n",
       "      <td>0.967485</td>\n",
       "      <td>0.895273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Name  accuracy  f1_score  log_loss  precision  \\\n",
       "0   AdaBoost | 10.0% of data  0.749000  0.751889  8.669233   0.760712   \n",
       "0   AdaBoost | 50.0% of data  0.742371  0.743587  8.898176   0.747366   \n",
       "0  AdaBoost | 100.0% of data  0.721543  0.720520  9.617569   0.722992   \n",
       "0        MLP | 10.0% of data  0.837286  0.834244  5.619952   0.841715   \n",
       "0        MLP | 50.0% of data  0.874686  0.873188  4.328202   0.876692   \n",
       "0       MLP | 100.0% of data  0.883429  0.881977  4.026235   0.886163   \n",
       "0        CNN | 10.0% of data  0.867143  0.862843  4.588723   0.868083   \n",
       "0        CNN | 50.0% of data  0.923371  0.923179  2.646657   0.924378   \n",
       "0       CNN | 100.0% of data  0.941800  0.941464  2.010157   0.942539   \n",
       "\n",
       "     recall   roc_auc  prec_rec_auc  \n",
       "0  0.749163  0.860646      0.619367  \n",
       "0  0.742739  0.857054      0.615169  \n",
       "0  0.721553  0.845308      0.586956  \n",
       "0  0.838094  0.910006      0.732207  \n",
       "0  0.875419  0.930747      0.787478  \n",
       "0  0.883997  0.935520      0.802150  \n",
       "0  0.864648  0.924962      0.773621  \n",
       "0  0.923170  0.957329      0.864555  \n",
       "0  0.941428  0.967485      0.895273  "
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat(tests)\n",
    "df.to_pickle(\"3a.pkl\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
